{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SriBhumika06/FMML-LAB-1/blob/main/FMML_Module_9_Lab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 9: Convolutional Neural Networks\n",
        "## **Lab 3**\n",
        "### Module coordinator: Kushagra Agarwal"
      ],
      "metadata": {
        "id": "kCpbL40ggQf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Understanding Convolutions"
      ],
      "metadata": {
        "id": "0hAW8ptqVeyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://miro.medium.com/max/464/0*e-SMFTzO8r7skkpc\" width=650px/>"
      ],
      "metadata": {
        "id": "q6wfvhccKxWx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZD5S7IQgHbU"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing some pytorch packages\n",
        "import torch\n",
        "from torch.nn import Conv2d"
      ],
      "metadata": {
        "id": "BDE4WBHalreb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Central to CNNs, a convolution operation is a linear element-wise multiplication operation between a small filter/kernel and same-sized patch from the image. We move this filter over the image like a sliding window from top left to bottom right. For each point on the image, a value is calculated based on the filter using a convolution operation. These filters can do simplest task like checking if there is a vertical line in the image or complicated task like detecting a human eye in the image.\n",
        "\n",
        "Let's look at the convolution formula:\n",
        "\n",
        "Convolution between image\n",
        "$f(x, y)$ and kernel $k(x, y)$ is\n",
        "$$f(x,y) * k(x,y) = \\sum \\limits _{i=0} ^{W-1} \\sum \\limits _{j=0} ^{H-1} f(i, j) k(x − i, y − j)$$\n",
        "\n",
        "where $W$ and $H$ are the the width and height of the image.\n",
        "\n",
        "The code demonstrates the convolution operation of a 2D matrix (image) with various filters"
      ],
      "metadata": {
        "id": "hbpRXyTpVv7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.researchgate.net/profile/Chaim-Baskin/publication/318849314/figure/fig1/AS:614287726870532@1523469015098/Image-convolution-with-an-input-image-of-size-7-7-and-a-filter-kernel-of-size-3-3.png\" alt=\"Convolution\" width=650px height=280px/>"
      ],
      "metadata": {
        "id": "amI6DTS0Ksvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D 3x3 binary image with vertical edge\n",
        "image1 = np.array([[1,1,0], [1,1,0], [1,1,0]])\n",
        "\n",
        "# 2D 3x3 binary image with horizontal edge\n",
        "image2 = np.array([[0,0,0], [0,0,0], [1,1,1]])\n",
        "\n",
        "# On plotting the images\n",
        "plt.imshow(image1, cmap='gray', extent=[0, 3, 3, 0])\n",
        "plt.show()\n",
        "plt.imshow(image2, cmap='gray', extent=[0, 3, 3, 0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IalqupPPkDil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vertical Line filter\n",
        "filter = np.array([[1,0,-1],\n",
        "                   [1,0,-1],\n",
        "                   [1,0,-1]])\n",
        "\n",
        "# Applying filter to first image\n",
        "output = np.sum(np.multiply(image1, filter))\n",
        "print('Output from first image: ', output)\n",
        "\n",
        "# Applying filter to second image\n",
        "output = np.sum(np.multiply(image2, filter))\n",
        "print('Output from second image: ', output)"
      ],
      "metadata": {
        "id": "g42INjCaketK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Horizontal edge filter\n",
        "filter = np.array([[-1,-1,-1],\n",
        "                   [ 0, 0, 0],\n",
        "                   [ 1, 1, 1]])\n",
        "\n",
        "output = np.sum(np.multiply(image1, filter))\n",
        "print('Output from first image: ', output)\n",
        "\n",
        "output = np.sum(np.multiply(image2, filter))\n",
        "print('Output from second image: ', output)"
      ],
      "metadata": {
        "id": "Tba3ySYUk2df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non-zero output suggests that there is a vertical edge present in the first image and not present in the second image. Similarly, horizontal edge is detected in second."
      ],
      "metadata": {
        "id": "BmYcPhDgk_in"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define a function to use convolution layer from Pytorch and use our own kernel to detect edges in image"
      ],
      "metadata": {
        "id": "UNdrDtAKqyj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_conv(image, kernel, padding=0, stride=1):\n",
        "\n",
        "  #--------IMAGE PREPROCESSING-------\n",
        "  image = torch.from_numpy(image)\n",
        "  # Pytorch requires input to convolution in (N,C,H,W), where N = batch size and C=#channels in input\n",
        "  input = image.view((1,1,image.shape[0], image.shape[1]))\n",
        "\n",
        "  # --------------KERNEL-------------\n",
        "  kernel = torch.from_numpy(kernel.astype(np.float32))\n",
        "\n",
        "  # Pytorch requires kernel of shape (N,C,H,W), where N = batch size and C=#channels in input\n",
        "  kernel = kernel.view((1,1,kernel.shape[0], kernel.shape[1]))\n",
        "\n",
        "  # ---------CONVOLUTION LAYER from Pytorch--------\n",
        "  conv = Conv2d(in_channels=1, out_channels=1, kernel_size=kernel.shape, padding=padding, stride=stride)\n",
        "\n",
        "  # Set the kernel weights in the convolution layer\n",
        "  conv.weight = torch.nn.Parameter(kernel)\n",
        "\n",
        "  # ---------APPLY CONVOLUTION--------\n",
        "  output = conv(input.float())\n",
        "  output_img = output.data.numpy()  # Tensor to back in numpy\n",
        "  output_img = output_img.reshape((-1, output_img.shape[-1])) # Reshape to 2D image\n",
        "\n",
        "  return output_img"
      ],
      "metadata": {
        "id": "G5fRJziBk3YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our original lotus image\n",
        "image = cv2.imread('/content/grid1 (1).jpg', 0)\n",
        "\n",
        "filter = np.array([[-1,-1,-1],\n",
        "                   [ 0, 0, 0],\n",
        "                   [ 1, 1, 1]])\n",
        "\n",
        "out1 = apply_conv(image, filter, padding=0, stride=1)\n",
        "\n",
        "filter = np.array([[1,0,-1],\n",
        "                   [1,0,-1],\n",
        "                   [1,0,-1]])\n",
        "\n",
        "out2 = apply_conv(image, filter, padding=0, stride=1)"
      ],
      "metadata": {
        "id": "1HPV6fFZloyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10,6))\n",
        "ax = fig.add_subplot(1,3,1)\n",
        "ax.imshow(image, cmap='gray')\n",
        "ax.set_title('Original Image')\n",
        "ax = fig.add_subplot(1,3,2)\n",
        "ax.set_title('Horizontal edge')\n",
        "ax.imshow(out1, cmap='gray')\n",
        "ax = fig.add_subplot(1,3,3)\n",
        "ax.imshow(out2, cmap='gray')\n",
        "ax.set_title('Vertical edge')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xgwXwbUKnmEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling Layers\n",
        "\n",
        "Pooling layers are used to reduce the dimensions of the feature maps. Thus, it reduces the number of parameters to learn and the amount of computation performed in the network. The pooling layer summarises the features present in a region of the feature map generated by a convolution layer.\n",
        "\n",
        "1) Max Pooling:\n",
        "\n",
        "<img src='https://media.geeksforgeeks.org/wp-content/uploads/20190721025744/Screenshot-2019-07-21-at-2.57.13-AM.png' height=150px/>\n",
        "\n",
        "2) Average Pooling:\n",
        "\n",
        "<img src='https://media.geeksforgeeks.org/wp-content/uploads/20190721030705/Screenshot-2019-07-21-at-3.05.56-AM.png' height=150px/>"
      ],
      "metadata": {
        "id": "FpA0yEk1BgRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax layer/activation\n",
        "Recall that logistic regression produces a decimal between 0 and 1.0. For example, a logistic regression output of 0.8 from an email classifier suggests an 80% chance of an email being spam and a 20% chance of it being not spam. Clearly, the sum of the probabilities of an email being either spam or not spam is 1.0.\n",
        "\n",
        "Softmax extends this idea into a multi-class world. That is, Softmax assigns decimal probabilities to each class in a multi-class problem. Those decimal probabilities must add up to 1.0. This additional constraint helps training converge more quickly than it otherwise would.\n",
        "Softmax is implemented through a neural network layer just before the output layer. The Softmax layer must have the same number of nodes as the output layer.\n",
        "\n",
        "<img src='https://miro.medium.com/max/1400/1*ReYpdIZ3ZSAPb2W8cJpkBg.jpeg' height=170px />"
      ],
      "metadata": {
        "id": "eu3QIU7AEO_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning to train a CNN network"
      ],
      "metadata": {
        "id": "P6grxC0TKKSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "qlO-uZUHnn_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Images returned from torchvision dataset classes is in range [0,1]\n",
        "# We transform them to tensors and normalize them to range [-1,1] using 'Normalize' transform\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Classes in CIFAR10\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "NnezCUbwGqzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training data shape : ', trainset.data.shape, len(trainset.targets))\n",
        "print('Testing data shape : ', testset.data.shape, len(testset.targets))\n",
        "\n",
        "# Find the unique numbers from the train labels\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)"
      ],
      "metadata": {
        "id": "e2M57DhHGupn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs, model, train_loader, loss_func, optimizer):\n",
        "\n",
        "  # Training mode\n",
        "  model.train()\n",
        "\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "\n",
        "  # Train the model\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "      # clear gradients for this training step\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      output = model(images)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = loss_func(output, labels)\n",
        "\n",
        "      # Backpropagation, compute gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # Apply gradients\n",
        "      optimizer.step()\n",
        "\n",
        "      # Running loss\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # indices of max probabilities\n",
        "      _, preds = torch.max(output, dim=1)\n",
        "\n",
        "      # Calculate number of correct predictions\n",
        "      correct = (preds.float() == labels).sum()\n",
        "      running_acc += correct\n",
        "\n",
        "      # Average loss and acc values\n",
        "      epoch_loss = running_loss / len(train_loader.dataset)\n",
        "      epoch_acc = running_acc / len(train_loader.dataset)\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    print ('Epoch {}/{}, Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch + 1, num_epochs, epoch_loss, epoch_acc*100))\n",
        "\n",
        "  return train_losses, train_acc"
      ],
      "metadata": {
        "id": "_haw697lHCZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, testloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # Deactivate autograd engine (don't compute grads since we're not training)\n",
        "  with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # Calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # The class with the highest value is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network: %d %%' % (\n",
        "      100 * correct / total))"
      ],
      "metadata": {
        "id": "x1Wi6vW7IHcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN with 2 CONV layers and 3 FC layers\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "        self.fc1 = nn.Linear(32 * 5 * 5, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        # output layer 10 classes\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # flatten all dimensions except batch\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RgxbRadcHIms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "02meBxVOHLNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy loss for multi-class classification\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "lfKHypeYHNHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD optimizer with momentum\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)"
      ],
      "metadata": {
        "id": "MuDnJL28HPKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5  # iterations\n",
        "train_losses, train_acc = train(num_epochs, model, trainloader, criterion, optimizer)"
      ],
      "metadata": {
        "id": "AgKhwMrtHRCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10,4))\n",
        "ax = fig.add_subplot(1,2, 1)\n",
        "ax.plot(np.arange(1,len(train_losses)+1),train_losses)\n",
        "plt.xlabel('Training loss')\n",
        "plt.ylabel('Epochs')\n",
        "ax.set_title('Loss vs Epochs')\n",
        "ax = fig.add_subplot(1,2, 2)\n",
        "ax.plot(np.arange(1,len(train_acc)+1),train_acc)\n",
        "plt.xlabel('Training accuracy')\n",
        "plt.ylabel('Epochs')\n",
        "ax.set_title('Accuracy vs Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tM2wHKGuHToB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on test data after training\n",
        "test_model(model, testloader)"
      ],
      "metadata": {
        "id": "3sHK9hhmI-VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions\n",
        "1) List some reasons why we should prefer CNN over ANN for image classification?\n",
        "\n",
        "2) Try improving the CNN performance further by tuning the hyperparameters(epochs, optimizer, LR etc). Report the improved test accuracy.\n",
        "\n",
        "3) What happens if you reduce the number of convolution layers to only 1?\n",
        "\n",
        "4) Why didn't we use the Softmax activation in the last layer of CNN?\n"
      ],
      "metadata": {
        "id": "RBQeCEB6REnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer: 1**\n",
        "\n",
        "**Spatial Hierarchies:**\n",
        "\n",
        " CNNs are designed to preserve the spatial structure of the input data. They use convolutional layers to detect patterns at different spatial scales, allowing them to capture hierarchical features in images. ANNs, on the other hand, treat input data as a flat vector, ignoring spatial relationships.\n",
        "\n",
        "**Feature Reuse:**\n",
        "\n",
        " CNNs employ weight sharing through convolutional filters, which allows them to reuse learned features across different parts of the image. This significantly reduces the number of parameters needed to train the network compared to ANNs, making CNNs more efficient and less prone to overfitting.\n",
        "\n",
        "**Translation Invariance:**\n",
        "\n",
        " CNNs are inherently translation-invariant, meaning they can recognize patterns regardless of their position in the image. This property is achieved through the use of shared weights in convolutional layers. ANNs lack this property and require extensive data augmentation or additional layers to achieve translation invariance.\n",
        "\n",
        "**Local Connectivity:**\n",
        "\n",
        " CNNs exploit local connectivity by connecting each neuron to a small, localized region of the input data. This allows them to capture local patterns efficiently. ANNs, being fully connected, have to learn all possible connections, leading to increased computational complexity and overfitting.\n",
        "\n",
        "**Parameter Sharing:**\n",
        "\n",
        " CNNs share parameters across the entire input image, which makes them well-suited for tasks where the spatial location of features is irrelevant. This parameter sharing significantly reduces the number of parameters in the network, making CNNs more efficient and easier to train.\n",
        "\n",
        "**Better Performance:**\n",
        "\n",
        "CNNs have shown superior performance compared to ANNs in image-related tasks, achieving state-of-the-art results in tasks like image classification, object detection, and segmentating\n",
        "\n",
        "**pre-trained models :**\n",
        "\n",
        "Pre-trained CNN models (such as VGG, ResNet, or Inception) are readily available. These models are trained on large-scale image datasets (like ImageNet) and can be fine-tuned on specific tasks with smaller datasets, providing a good starting point for image classification tasks.\n",
        "\n",
        "Overall, CNNs are specifically designed to handle spatial data like images, and their architecture is optimized for capturing local patterns, hierarchical features, and translation invariance, making them the preferred choice for image classification tasks."
      ],
      "metadata": {
        "id": "kQ-S6vuM1z2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Answer:**\n",
        "\n",
        "**Split the Data:**\n",
        "\n",
        " Ensure you have separate training, validation, and test sets. This helps prevent overfitting and gives a reliable estimate of the model's performance.\n",
        "\n",
        "**Define Hyperparameters:**\n",
        "\n",
        " Choose a range of values to test for each hyperparameter.\n",
        "\n",
        "**For example: Number of epochs:**\n",
        "\n",
        "** 20, 30, 40 Optimizers:** Adam, SGD Learning rates: 0.001, 0.01, 0.1\n",
        "\n",
        "**Create a Grid for Hyperparameter Search:**\n",
        "\n",
        " You can use a grid search or random search to find the best combination of hyperparameters.\n",
        "\n",
        "**Train the Model:**\n",
        "\n",
        " For each combination of hyperparameters, train the model on the training set and validate on the validation set.\n",
        "\n",
        "**Select the Best Model:**\n",
        "\n",
        " Choose the model with the highest performance on the validation set.\n",
        "\n",
        "**Evaluate on Test Set:**\n",
        "\n",
        "Finally, evaluate the best model on the test set to get the final accuracy."
      ],
      "metadata": {
        "id": "wZsFaoV93A67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define CNN model\n",
        "def create_model(optimizer='adam', learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        opt = Adam(learning_rate=learning_rate)\n",
        "    else:\n",
        "        opt = SGD(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define hyperparameters\n",
        "epochs = [20, 30, 40]\n",
        "optimizers = ['adam', 'sgd']\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "best_hyperparameters = {}\n",
        "\n",
        "# Grid search for best hyperparameters\n",
        "for epoch in epochs:\n",
        "    for optimizer in optimizers:\n",
        "        for lr in learning_rates:\n",
        "            model = create_model(optimizer, lr)\n",
        "            history = model.fit(X_train, y_train, epochs=epoch, validation_data=(X_val, y_val), verbose=0)\n",
        "            val_accuracy = history.history['val_accuracy'][-1]\n",
        "            if val_accuracy > best_accuracy:\n",
        "                best_accuracy = val_accuracy\n",
        "                best_model = model\n",
        "                best_hyperparameters = {'epochs': epoch, 'optimizer': optimizer, 'learning_rate': lr}\n",
        "\n",
        "# Evaluate the best model on test set\n",
        "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Best Hyperparameters:\", best_hyperparameters)"
      ],
      "metadata": {
        "id": "M3fDtf1F3xFc",
        "outputId": "49fc0b74-2bc4-4dd0-c6ed-3ab9eb7f2bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Answer:**\n",
        "\n",
        "\n",
        "This code modifies the CNN architecture to have only one convolutional layer followed by max pooling and then two fully connected layers. After making this change, we'll see how the model performs compared to the previous version."
      ],
      "metadata": {
        "id": "lH80UfHn4JXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define CNN model with one convolutional layer\n",
        "def create_model(optimizer='adam', learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        opt = Adam(learning_rate=learning_rate)\n",
        "    else:\n",
        "        opt = SGD(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define hyperparameters\n",
        "epochs = [20, 30, 40]\n",
        "optimizers = ['adam', 'sgd']\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "best_hyperparameters = {}\n",
        "\n",
        "# Grid search for best hyperparameters\n",
        "for epoch in epochs:\n",
        "    for optimizer in optimizers:\n",
        "        for lr in learning_rates:\n",
        "            model = create_model(optimizer, lr)\n",
        "            history = model.fit(X_train, y_train, epochs=epoch, validation_data=(X_val, y_val), verbose=0)\n",
        "            val_accuracy = history.history['val_accuracy'][-1]\n",
        "            if val_accuracy > best_accuracy:\n",
        "                best_accuracy = val_accuracy\n",
        "                best_model = model\n",
        "                best_hyperparameters = {'epochs': epoch, 'optimizer': optimizer, 'learning_rate': lr}\n",
        "\n",
        "# Evaluate the best model on test set\n",
        "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Best Hyperparameters:\", best_hyperparameters)"
      ],
      "metadata": {
        "id": "rjmx9CS64dBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Answer: 4**\n",
        "\n",
        "\n",
        "some reasons why Softmax activation might not be used in the last layer:\n",
        "\n",
        "**Binary Classification:**\n",
        "\n",
        " If the task is binary classification (two classes), we typically use a single neuron with a sigmoid activation function. Sigmoid function squashes the output between 0 and 1, representing the probability of belonging to one of the two classes.\n",
        "\n",
        "**Multi-class Classification:**\n",
        "\n",
        " If the task is multi-class classification with more than two classes, Softmax activation is often used in the last layer. It's used to normalize the output into a probability distribution over multiple classes, ensuring that the sum of probabilities for all classes is 1.\n",
        "\n",
        "**Regression:**\n",
        "\n",
        " If the task is regression, where the output is a continuous value, the last layer might have a linear activation (no activation function) or a different activation function like ReLU depending on the nature of the output.\n",
        "\n",
        "**Custom Output Requirement:**\n",
        "\n",
        " In some cases, we might need a custom output format. For example, if we're dealing with object detection, the output layer might consist of multiple neurons with different activations and a custom loss function.\n",
        "\n",
        "**Loss Function Compatibility:**\n",
        "\n",
        " The choice of activation function in the output layer is often tied to the loss function. For example, if we're using categorical cross-entropy loss, Softmax activation is typically used. But if we're using binary cross-entropy loss, Sigmoid activation is more appropriate.\n",
        "\n",
        "In summary, the choice of activation function in the last layer of a CNN depends on the specific requirements of the task, the nature of the output, and the compatibility with the loss function being used. Softmax activation is just one of the options, and it's not always the best choice."
      ],
      "metadata": {
        "id": "qRRtmf304vT0"
      }
    }
  ]
}